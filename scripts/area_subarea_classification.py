# -*- coding: utf-8 -*-
"""POSCOMP - Text Classification.ipynb

Automatically generated by Colab.

# Instalação de dependências
"""

!pip install openai
!pip install pandas
!pip install tqdm

from openai import OpenAI
import pandas as pd

from tqdm import tqdm

tqdm.pandas()

API_KEY = "API_KEY"
BASE_URL = "https://api.deepinfra.com/v1/openai"

openai = OpenAI(
    api_key = API_KEY,
    base_url = BASE_URL,
)

model = "meta-llama/Llama-3.3-70B-Instruct"

"""# Leitura do *dataset*"""

poscomp_ds = pd.read_json("dataset.json")
poscomp_ds.drop_duplicates(subset = ['id'], inplace = True)
poscomp_ds = poscomp_ds.sort_values(by=['id'])
poscomp_ds.reset_index(drop = True, inplace = True)

poscomp_ds.head(5)

colunas_relevantes = [
    'id',
    'enunciado',
    'alternativas',
    'area_conhecimento'
]

poscomp_ds = poscomp_ds[colunas_relevantes]
poscomp_ds.head(5)

poscomp_ds['alternativas_str_completo'] = poscomp_ds['alternativas'].apply(lambda x: '\n'.join(map(str, x)))
poscomp_ds['alternativas_str_parcial'] = poscomp_ds['alternativas'].apply(lambda x: x[0])
poscomp_ds.head(5)

poscomp_ds['texto_completo'] = poscomp_ds['enunciado'] + '\n\n' + poscomp_ds['alternativas_str_completo']
poscomp_ds['texto_parcial'] = poscomp_ds['enunciado'] + '\n\n' + poscomp_ds['alternativas_str_parcial']

colunas_relevantes.extend(['texto_completo', 'texto_parcial'])
poscomp_ds = poscomp_ds[colunas_relevantes]

"""# Extração de comandos *LaTeX*"""

import re
from collections import Counter

def extrair_comandos_latex(texto):
    padrao_formulas = r"\$\$(.*?)\$\$|\$(.*?)\$"

    matches = re.findall(padrao_formulas, texto, re.DOTALL)

    comandos = []

    for match in matches:
        formula = match[0] if match[0] else match[1]
        comandos_encontrados = re.findall(r"\\[a-zA-Z]+", formula)
        comandos.extend(comandos_encontrados)

    return list(set(comandos))

poscomp_ds['comandos_latex'] = poscomp_ds['texto_completo'].apply(lambda x: extrair_comandos_latex(x))
poscomp_ds.head(5)

todos_comandos = []

for lista_comandos in poscomp_ds['comandos_latex']:
    todos_comandos.extend(lista_comandos)

latex_para_categoria = {
  "\\forall": "operador_lógico",
  "\\exists": "operador_lógico",
  "\\neg": "operador_lógico",
  "\\lnot": "operador_lógico",
  "\\land": "operador_lógico",
  "\\lor": "operador_lógico",
  "\\to": "operador_lógico",
  "\\Rightarrow": "operador_lógico",
  "\\Leftrightarrow": "operador_lógico",
  "\\leftrightarrow": "operador_lógico",
  "\\iff": "operador_lógico",
  "\\not": "operador_lógico",
  '\\oplus': 'operador_lógico',
  '\\sim': 'operador_lógico', # manual

  "\\in": "operador_conjunto",
  "\\notin": "operador_conjunto",
  "\\subset": "operador_conjunto",
  "\\subseteq": "operador_conjunto",
  "\\subsetneq": "operador_conjunto",
  "\\nsubset": "operador_conjunto",
  "\\cup": "operador_conjunto",
  "\\cap": "operador_conjunto",
  "\\setminus": "operador_conjunto",
  "\\varnothing": "operador_conjunto",
  "\\preceq": "operador_conjunto",
  "\\emptyset": "operador_conjunto",

  "\\sum": "somatório",
  "\\prod": "produtório",
  "\\int": "integral",
  "\\lim": "limite",
  "\\mod": "módulo",
  "\\pmod": "módulo",
  "\\binom": "binômio",
  "\\det": "determinante",
  "\\nabla": "gradiente",
  "\\partial": "derivada",
  "\\log": "logaritmo",
  "\\ln": "logaritmo",
  "\\lg": "logaritmo",
  "\\exp": "exponencial",
  '\\perp': "operador_geométrico",

  "\\sin": "função_trigonométrica",
  "\\cos": "função_trigonométrica",
  "\\arctan": "função_trigonométrica",

  "\\bowtie": "operador_relacional",

  "\\vec": "vetor",
  "\\overrightarrow": "vetor",

  "\\alpha": "letra_grega",
  "\\beta": "letra_grega",
  "\\gamma": "letra_grega",
  "\\theta": "letra_grega",
  "\\lambda": "letra_grega",
  "\\mu": "letra_grega",
  "\\pi": "letra_grega",
  "\\sigma": "letra_grega",
  "\\rho": "letra_grega",
  "\\phi": "letra_grega",
  "\\varphi": "letra_grega",
  "\\varepsilon": "letra_grega",
  "\\epsilon": "letra_grega",
  "\\omega": "letra_grega",
  "\\Omega": "letra_grega",
  "\\Phi": "letra_grega",
  "\\Sigma": "letra_grega",
  "\\eta": "letra_grega",
  "\\Theta": "letra_grega",

  "\\begin": "ignorar",
  "\\text": "ignorar",
  "\\textbf": "ignorar",
  "\\texttt": "ignorar",
  "\\textnormal": "ignorar",

  "\\frac": "ignorar",
  "\\dfrac": "ignorar",
  "\\sqrt": "ignorar",
  "\\cdot": "ignorar",
  "\\times": "ignorar",
  "\\div": "ignorar",
  "\\pm": "ignorar",

  "\\end": "ignorar",
  "\\min": "ignorar",
  "\\max": "ignorar",
  "\\hline": "ignorar",
  "\\circ": "ignorar",
  "\\twoheadrightarrow": "ignorar", # manual
  "\\updownarrow": "ignorar", # manual
  "\\rightarrow": "ignorar", # manual
  "\\leftarrow": "ignorar", # manual
  '\\displaystyle': 'ignorar',
  '\\infty': 'ignorar',
  '\\lceil': 'ignorar',
  '\\lfloor': 'ignorar',
  '\\rceil': 'ignorar',
  '\\rfloor': 'ignorar',
  "\\dots": "ignorar",
  "\\dotsx": "ignorar",
  "\\cdots":"ignorar",
  "\\ldots": "ignorar",

  "\\prime": "ignorar",
  "\\overline": "ignorar",
  "\\bar": "ignorar",
  "\\limits": "ignorar",
  "\\underset": "ignorar",

   "\\leq": "ignorar",
  "\\le": "ignorar",
  "\\geq": "ignorar",
  "\\ge": "ignorar",
  "\\neq": "ignorar",
  "\\ne": "ignorar",
  "\\approx":"ignorar",
  "\\equiv": "ignorar",

  "\\mathbb": "ignorar",
  "\\mathbf": "ignorar",
  "\\mathit": "ignorar",
  "\\mathcal": "ignorar",
  "\\cal": "ignorar",

  "\\quad": "ignorar",
  "\\left": "ignorar",
  "\\right": "ignorar",
  "\\langle": "ignorar",
  "\\rangle": "ignorar",
  "\\lvert": "ignorar",
  "\\rvert": "ignorar",
  "\\lVert": "ignorar",
  "\\rVert": "ignorar",
  "\\mid": "ignorar",
  "\\Vert": "ignorar",
  "\\vert": "ignorar"
}

set(latex_para_categoria.keys()) == set(todos_comandos)

def substituir_formula_por_categorias(texto, latex_para_categoria):
    padrao_formulas = r"\$\$(.*?)\$\$|\$(.*?)\$"

    def substituir_formula(match):
        formula = match.group(1) if match.group(1) else match.group(2)
        comandos = re.findall(r"\\[a-zA-Z]+", formula)
        categorias = set()
        for cmd in comandos:
            cat = latex_para_categoria.get(cmd)
            if cat and cat != "ignorar":
                categorias.add(cat)

        if categorias:
            return "" + ", ".join(sorted(categorias)) + ""
        else:
            return "[fórmula]"

    return re.sub(padrao_formulas, substituir_formula, texto, flags=re.DOTALL)

poscomp_ds['texto_substituido'] = poscomp_ds['texto_completo'].map(lambda x: substituir_formula_por_categorias(x, latex_para_categoria))
poscomp_ds['texto_substituido_parcial'] = poscomp_ds['texto_parcial'].map(lambda x: substituir_formula_por_categorias(x, latex_para_categoria))

poscomp_ds[['id', 'texto_substituido_parcial']].to_csv('to_merge.csv', index = False)

"""# Cálculo de *tokens* para estimativa de custo"""

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.3-70B-Instruct")

poscomp_ds['tokens_parcial'] = poscomp_ds['texto_parcial'].apply(lambda x: len(tokenizer(x)['input_ids']))
poscomp_ds['tokens_completo'] = poscomp_ds['texto_completo'].apply(lambda x: len(tokenizer(x)['input_ids']))
poscomp_ds['tokens_substituido'] = poscomp_ds['texto_substituido'].apply(lambda x: len(tokenizer(x)['input_ids']))
poscomp_ds['tokens_substituido_parcial'] = poscomp_ds['texto_substituido_parcial'].apply(lambda x: len(tokenizer(x)['input_ids']))

poscomp_ds.head()

soma_tokens_completo = poscomp_ds['tokens_completo'].sum() / 1e6
soma_tokens_parcial = poscomp_ds['tokens_parcial'].sum() / 1e6
soma_tokens_substituido = poscomp_ds['tokens_substituido'].sum() / 1e6
soma_tokens_substituido_parcial = poscomp_ds['tokens_substituido_parcial'].sum() / 1e6

print(f"- conteúdo integral (original):                {soma_tokens_completo:.2f} Mtokens\n"
      f"- conteúdo integral (transformado):            {soma_tokens_substituido:.2f} Mtokens\n"
      f"- diferença (original - transformado):         {(soma_tokens_completo - soma_tokens_substituido):.2f} Mtokens\n\n"
      f"- conteúdo parcial (original):                 {soma_tokens_parcial:.2f} Mtokens\n"
      f"- conteúdo parcial (transformado):             {soma_tokens_substituido_parcial:.2f} Mtokens\n"
      f"- diferença (original - transformado):         {(soma_tokens_parcial - soma_tokens_substituido_parcial):.2f} Mtokens\n\n"
      f"- diferença (original1 - transformado2):       {(soma_tokens_completo - soma_tokens_substituido_parcial):.2f} Mtokens\n"
      f"- diferença percentual:                        {100 * (soma_tokens_substituido_parcial - soma_tokens_completo)/(soma_tokens_completo):.2f}%")

"""# Listagem de áreas e subáreas"""

areas_matematica = {
  "Álgebra Linear": [
    "Sistemas de Equações Lineares: método de eliminação de Gauss para sistemas lineares",
    "Espaços vetoriais",
    "Subespaços",
    "Bases",
    "Somas Diretas",
    "Introdução à Programação Linear",
    "Transformações Lineares e Matrizes",
    "Autovalores e Autovetores",
    "Diagonalização",
    "Espaços com Produto Interno",
    "Bases Ortonormais",
    "Projeções Ortogonais",
    "Movimentos Rígidos",
    "Método dos Mínimos Quadrados",
    "Transformações em Espaços com Produto Interno",
    "O Teorema da Representação para Funções Lineares",
    "Adjunta de uma Transformação Linear",
    "Operadores Simétricos, Unitários, Ortogonais e Normais",
    "O Teorema Espectral",
    "Formas Canônicas",
  ],
  "Análise Combinatória": [
    "Distribuição",
    "Permutações",
    "Combinações",
    "Funções Geradoras Ordinárias e Exponenciais",
    "Princípio de Inclusão e Exclusão",
    "Enumeração de Partições, Grafos, Árvores e Redes",
    "Enumeração por Recursão",
    "Permutações com Posições Restritas"
  ],
    "Cálculo Diferencial e Integral" : [
    "Limites de Funções e de Sequências",
    "Funções Reais de uma Variável: Continuidade e Diferenciabilidade",
    "Máximos e Mínimos",
    "Fórmula de Taylor e Aproximação de Funções",
    "Método de Newton para o Cálculo de Raízes e de Máximos e Mínimos",
    "Integração de Funções Reais de uma Variável",
    "Métodos de Integração",
    "Integração Aproximada",
    "Regras dos Trapézios, de Simpson e Generalizadas",
    "Funções de Várias Variáveis: Continuidade e Diferenciabilidade",
    "Gradiente",
    "Máximos e Mínimos",
    "Multiplicadores de Lagrange",
    "Transformações",
    "Matrizes Jacobianas",
    "Teorema da Função Inversa",
    "Diferenciação Implícita",
    "Integração de Funções de Várias Variáveis",
    "Mudanças de Coordenadas em Integrais",
    "Integral de Linha"
  ],
  "Geometria Analítica": [
    "Matrizes",
    "Sistemas de Equações Lineares",
    "Vetores",
    "Produtos: escalar, vetorial e misto",
    "Álgebra Vetorial",
    "Reta no plano e no espaço",
    "Planos",
    "Posições Relativas, Interseções, Distâncias e Ângulos",
    "Círculo e Esfera",
    "Coordenadas Polares, Cilíndricas e Esféricas"
  ],
  "Lógica Matemática": [
    "Lógica Proposicional e de Predicados",
    "Linguagem Proposicional e de Primeira Ordem",
    "Sistemas Dedutivos",
    "Tabelas Verdade e Estruturas de Primeira Ordem",
    "Relações de Consequência",
    "Corretude",
    "Completude",
    "Compacidade",
    "Lowemhein-Skolem",
    "Decidibilidade",
    "Prova Automática de Teoremas",
    "Lógicas não clássicas"
  ],
  "Matemática Discreta": [
    "Iteração, Indução e Recursão",
    "Conjuntos e Álgebra de Conjuntos como uma Teoria Axiomática",
    "Par Ordenado",
    "Funções",
    "Funções e Formas Booleanas, Álgebra Booleana, Minimização de Funções Booleanas",
    "Relações sobre Conjuntos, Relações de Equivalência e Ordem",
    "Reticulados, Monóides, Grupos, Anéis",
    "Teoria dos Códigos, Canal Binário, Canal Simétrico, Código de Blocos, Matrizes Geradoras e Verificadoras, Códigos de Grupo, Códigos de Hamming",
    "Teoria dos Domínios: Ordens Parciais Completas, Continuidade, Ponto Fixo, Domínios, Espaço das Funções"
  ],
  "Probabilidade e Estatística": [
    "Eventos",
    "Experimentos Aleatórios",
    "Análise Exploratória de Dados",
    "Descrição Estatística dos Dados",
    "Espaços Amostrais",
    "Probabilidades em Espaços Amostrais Discretos",
    "Distribuições de Probabilidades de Variáveis Aleatórias Unidimensionais e Bidimensionais",
    "Esperança Matemática",
    "Variância e Coeficientes de Correlação",
    "Aproximação Normal",
    "Estimação Pontual e por Intervalo",
    "Teste de Hipóteses para Médias",
    "Testes do Qui-Quadrado",
    "Testes de Comparações de Médias",
    "Regressão e Correlação"
  ]
}

areas_fundamentos = {
  "Análise de Algoritmos": [
    "Medidas de Complexidade, Análise Assintótica de Limites de Complexidade, Técnicas de Prova de Cotas Inferiores",
    "Notação “Big O”, “Little o”, “Omega” e “Theta”",
    "Medidas Empíricas de Performance",
    "O Uso de Relações de Recorrência para Análise de Algoritmos Recursivos",
    "Análise de Algoritmos Iterativos e Recursivos"
  ],
  "Algoritmos e Estrutura de Dados": [
    "Metodologia de Desenvolvimento de Algoritmos",
    "Tipos de Dados Básicos e Estruturados",
    "Comandos de uma Linguagem de Programação",
    "Recursividade: Conceito e Implementação",
    "Modularidade e Abstração",
    "Estratégias de Depuração",
    "Cadeias e Processamento de Cadeias",
    "Estruturas de Dados Lineares e suas Generalizações: Listas Ordenadas, Listas Encadeadas, Pilhas e Filas",
    "Árvores e suas Generalizações: Árvores Binárias, Árvores de Busca e Árvores Balanceadas",
    "Tabelas Hash",
    "Algoritmos para Pesquisa e Ordenação",
    "Algoritmos para “Garbage Collection”",
    "Técnicas de Projeto de Algoritmos: Método da Força Bruta, Pesquisa Exaustiva, Algoritmo Guloso, Dividir e Conquistar, “Backtracking” e Heurísticas",
  ],
  "Arquitetura e Organização de Computadores": [
    "Organização de Computadores: Memórias, Unidades Centrais de Processamento, Entrada e Saída",
    "Linguagens de Montagem",
    "Modos de Endereçamento, Conjunto de Instruções",
    "Mecanismos de Interrupção e de Exceção",
    "Barramento, Comunicações, Interfaces e Periféricos",
    "Organização de Memória",
    "Memória Auxiliar",
    "Arquiteturas RISC e CISC",
    "Pipeline",
    "Paralelismo de Baixa Granularidade",
    "Processadores Superescalares e Superpipeline",
    "Multiprocessadores",
    "Multicomputadores",
    "Arquiteturas Paralelas e não Convencionais"
  ],
  "Circuitos Digitais": [
    "Sistemas de Numeração e Códigos",
    "Aritmética Binária",
    "Representação e Manipulação de Circuitos Combinatórios",
    "Minimização e Otimização de Funções Combinatórias",
    "Projeto de Circuitos Combinatórios",
    "Análise e Síntese de Componentes Sequenciais e de Memória",
    "Projeto de Circuitos Sequenciais",
    "Modelo de Máquinas de Estado Finito (FSM)",
    "Circuitos Sequenciais Síncronos e Assíncronos",
    "Componentes de Armazenamento",
    "Projeto de Sistemas Digitais: Hierárquico e Modular",
    "Princípios e Técnicas de Projeto",
    "Conceitos de Controle e de Tempo",
    "Famílias Lógicas",
    "Dispositivos Lógicos Programáveis (PLD)"
  ],
  "Linguagens de Programação": [
    "Conceitos",
    "Paradigmas de Linguagens de Programação",
    "Semântica Formal",
    "Teoria dos Tipos: Sistemas de Tipos, Polimorfismo",
    "Verificação e Inferência de Tipos"
  ],
  "Linguagens Formais, Autômatos e Computabilidade": [
    "Gramáticas",
    "Linguagens Regulares, Livres-de-Contexto e Sensíveis-ao-Contexto",
    "Tipos de Reconhecedores",
    "Operações com Linguagens",
    "Propriedades das Linguagens",
    "Autômatos de Estados Finitos Determinístico e não Determinístico",
    "Autômatos de Pilha",
    "Máquina de Turing",
    "Hierarquia de Chomsky",
    "Funções Recursivas",
    "Tese de Church",
    "Problemas Indecidíveis",
    "Teorema da Incompletude de Godel",
    "Classes de Problemas P, NP, NP Completo e NP-Difícil",
    "Métodos de Redução de Problemas"
  ],
  "Organização de Arquivos e Dados": [
    "Organização, Estrutura e Operação de Arquivos",
    "Diretórios: Conteúdo e Estrutura",
    "Arquivos do Sistema e Sistema de Arquivos Virtuais",
    "Técnicas de Pesquisa",
    "Dados e Metadados",
    "Representação Digital e Analógica",
    "Algoritmos de Codificação e Decodificação",
    "Compressão de Dados, Áudio, Imagem e Vídeo"
  ],
  "Sistemas Operacionais": [
    "Conceito de Processo",
    "Gerência de Processos/Processador",
    "Comunicação, Concorrência e Sincronização de Processos",
    "Gerenciamento de Memória: Memória Virtual, Paginação, Segmentação e “Swap”",
    "Gerenciamento de Arquivos",
    "Gerenciamento de Dispositivos de Entrada/Saída",
    "Alocação de Recursos"
  ],
  "Técnicas de Programação" : [
    "Desenvolvimento de algoritmos",
    "Tipos de dados básicos e estruturados",
    "Comandos de uma Linguagem de programação",
    "Metodologia de desenvolvimento de programas",
    "Modularidade e abstração"
  ],
  "Teoria dos Grafos": [
    "Grafos orientados e não-orientados",
    "Caminhos",
    "Planaridade",
    "Conectividade",
    "Coloração",
    "Grafos Infinitos",
    "Algoritmos em grafos",
    "Problemas intratáveis",
    "Busca em Largura e Profundidade",
    "Algoritmos do Menor Caminho",
    "Árvore Geradora",
    "Ordenação Topológica"
  ]
}

areas_tecnologia = {
  "Banco de Dados": [
    "Modelo de Dados",
    "Modelagem e Projeto de Banco de Dados",
    "Sistemas de Gerenciamento de Bancos de Dados (SGBD): Arquitetura, Segurança, Integridade, Concorrência, Recuperação após Falha, Gerenciamento de Transações",
    "Linguagens de Consulta",
    "Bancos de Dados Distribuídos",
    "Mineração de Dados"
  ],
  "Compiladores": [
    "Compiladores e Interpretadores",
    "Análise Léxica e Sintática",
    "Tabelas de Símbolos",
    "Esquemas de Tradução",
    "Ambientes de Tempo de Execução",
    "Representação Intermediária",
    "Análise Semântica",
    "Geração de Código",
    "Otimização de Código",
    "Bibliotecas e Compilação em Separado"
  ],
  "Computação Gráfica": [
    "Transformações Geométricas em Duas e Três Dimensões: Coordenadas Homogêneas e Matrizes de Transformação",
    "Transformação entre Sistemas de Coordenadas 2D e Recorte",
    "Transformações de Projeção Paralela e Perspectiva",
    "Câmera Virtual",
    "Transformação entre Sistemas de Coordenadas 3D",
    "Definição de Objetos e Cenas Tridimensionais: Modelos Poliedrais e Malhas de Polígonos",
    "O Processo de “Rendering”: Fontes de Luz, Remoção de Linhas e Superfícies Ocultas, Modelos de Tonalização (“Shading”)",
    "Aplicação de Texturas",
    "O problema do Serrilhado (“Aliasing”) e Técnicas de Anti-Serrilhado (“Antialiasing”)",
    "Visualização"
  ],
  "Engenharia de Software": [
    "Processo de Desenvolvimento de Software",
    "Ciclo de Vida de Desenvolvimento de Software",
    "Qualidade de Software",
    "Técnicas de Planejamento e Gerenciamento de Software",
    "Gerenciamento de Configuração de Software",
    "Engenharia de Requisitos",
    "Métodos de Análise e de Projeto de Software",
    "Garantia de Qualidade de Software",
    "Verificação, Validação e Teste",
    "Manutenção",
    "Documentação",
    "Padrões de Desenvolvimento",
    "Reuso",
    "Engenharia Reversa",
    "Reengenharia",
    "Ambientes de Desenvolvimento de Software"
  ],
  "Inteligência Artificial": [
    "Linguagens Simbólicas",
    "Programação em Lógica",
    "Resolução de Problemas como Busca",
    "Estratégias de Busca, Busca Cega e Busca Heurística",
    "Hill climbing, best first, simulated annealing e Algoritmo A*",
    "Busca como Maximização de Função",
    "Grafos And/Or",
    "Esquemas para Representação do Conhecimento: Lógicos, em Rede, Estruturados, Procedurais",
    "Sistemas de Produção com Encadeamento para a Frente e Encadeamento para trás",
    "Raciocínio Não-Monotônico",
    "Formalismos para a Representação de Conhecimento Incerto",
    "A Regra de Bayes",
    "Conjuntos e Lógica Fuzzy",
    "Aprendizado de Máquina",
    "Aprendizado Indutivo",
    "Árvores de Decisão, Redes Neurais e Algoritmos Genéticos",
    "Sistemas Especialistas",
    "Processamento de Linguagem Natural",
    "Agentes Inteligentes",
    "Robótica"
  ],
  "Processamento de Imagens": [
    "Introdução aos Filtros Digitais",
    "Métodos de Espaço de Estados",
    "Noções de Percepção Visual Humana",
    "Amostragem e Quantização de Imagens",
    "Transformadas de Imagens",
    "Realce",
    "Filtragem e Restauração",
    "Reconstrução Tomográfica de Imagens",
    "Codificação",
    "Análise de Imagens e Noções de Visão Computacional",
    "Reconhecimento de Padrões",
  ],
  "Redes de Computadores": [
    "Tipos de Enlace, Códigos, Modos e Meios de Transmissão",
    "Protocolos e Serviços de Comunicação",
    "Terminologia, Topologias, Modelos de Arquitetura e Aplicações",
    "Especificação de Protocolos",
    "Internet e Intranets",
    "Interconexão de Redes",
    "Redes de Banda Larga",
    "Segurança e Autenticação",
    "Avaliação de Desempenho"
  ],
  "Sistemas Distribuídos": [
    "Problemas Básicos em Computação Distribuída: Coordenação e Sincronização de Processos, Exclusão Mútua, Difusão de Mensagens",
    "Compartilhamento de Informação: Controle de Concorrência, Transações Distribuídas",
    "Comunicação entre Processos",
    "Tolerância a Falhas",
    "Sistemas Operacionais Distribuídos: Sistemas de Arquivos, Servidores de Nomes, Memória Compartilhada, Segurança"
  ]
}

conteudo_poscomp = {
  "Matemática": areas_matematica,
  "Fundamentos da Computação": areas_fundamentos,
  "Tecnologia de Computação": areas_tecnologia
}

"""# Geração de *prompts*"""

def gerar_listagem_areas(areas):
  listagem = ""
  for index, area in enumerate(areas):
    listagem += f"{index + 1}. {area}\n"
  return listagem

def gerar_prompt_area(questao):
  area_conhecimento = questao['area_conhecimento']

  areas = conteudo_poscomp[area_conhecimento]

  areas_string = gerar_listagem_areas(areas)
  PROMPT = f"""Questão:
{questao['texto_completo']}

Áreas disponíveis:
{areas_string}
Responda apenas o número da área correspondente:
"""

  return PROMPT

SYSTEM_PROMPT = """Você é um classificador automático de questões. Você receberá uma questão simplificada, contendo seu enunciado e uma alternativa.
Sua tarefa é analisar o conteúdo da questão apresentada e classificá-la em uma área dentre as listadas, respondendo apenas com o número correspondente à opção mais adequada.
Nunca tente resolver a questão.
Responda apenas com o número. Nenhum outro texto deve ser incluído."""

def get_completion(prompt, model, system_prompt):
    chat_completion = openai.chat.completions.create(
        model = model,
        messages = [
            { "role": "system", "content": system_prompt },
            { "role": "user", "content": prompt }
        ],
        temperature = 0.7,
    )

    return chat_completion

"""Estimativa de aumento de custo pelo system prompt:"""

tokens_system_prompt = len(tokenizer(SYSTEM_PROMPT)['input_ids'])
print(f"${(0.23 * 1400 * tokens_system_prompt) / 1e6:.2f}/iteração")

poscomp_ds['prompt_area'] = poscomp_ds.apply(gerar_prompt_area, axis = 1)
poscomp_ds['tokens_prompt'] = poscomp_ds['prompt_area'].apply(lambda x: len(tokenizer(x)['input_ids']))

poscomp_ds.head(5)

biggest_prompt = poscomp_ds['tokens_prompt'].max()
line_with_biggest_prompt = poscomp_ds[poscomp_ds['tokens_prompt'] == biggest_prompt]
line_with_biggest_prompt

poscomp_ds['tokens_prompt'].describe()

plot_tokens = poscomp_ds['tokens_prompt'].plot(kind = 'box')

print(f"Estimativa de 1 iteração (usando total de tokens): ${(0.23 * poscomp_ds['tokens_prompt'].sum() / 1e6):.2f}")

"""# Experimentação

## Organização do dataset
"""

colunas_interesse = [
  'id',
  'enunciado',
  'area_conhecimento',
  'texto_completo',
  'prompt_area',
  'tokens_prompt'
]

poscomp_ds = poscomp_ds[colunas_interesse]
poscomp_ds.head(5)

def recupera_resposta_custo(questao):
  obj = get_completion(questao['prompt_area'], "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT)
  return (obj.choices[0].message.content, obj.usage.estimated_cost)

recupera_resposta_custo(poscomp_ds.iloc[0])

def iteracao_prompt(dataset, n_iteracao):
  results = dataset.progress_apply(lambda x: recupera_resposta_custo(x), axis = 1)

  dataset[f'area_{n_iteracao}'] = results.apply(lambda x: x[0])

  dataset[f'custo_{n_iteracao}'] = results.apply(lambda x: x[1])

  return dataset

"""# Execuções do *prompt* de áreas

## Primeiras três iterações
"""

poscomp_ds = iteracao_prompt(poscomp_ds, 1)

Counter(poscomp_ds['area_1'])

poscomp_ds = iteracao_prompt(poscomp_ds, 2)

Counter(poscomp_ds['area_2'])

poscomp_ds = iteracao_prompt(poscomp_ds, 3)

Counter(poscomp_ds['area_3'])

print(f"Iteração 1: ${poscomp_ds['custo_1'].sum():.3f}\n"
f"Iteração 2: ${poscomp_ds['custo_2'].sum():.3f}\n"
f"Iteração 3: ${poscomp_ds['custo_3'].sum():.3f}")

"""## Consolidar *Self-Consistency*"""

def definir_area(questao):
    if questao['area_1'] == questao['area_2'] == questao['area_3']:
        return questao['area_1']
    else:
        return -1

poscomp_ds['area_final'] = poscomp_ds.apply(definir_area, axis = 1)

Counter(poscomp_ds['area_final'])

"""Definindo subconjunto para executar mais duas iterações:"""

subset_iteracao = poscomp_ds[poscomp_ds['area_final'] == -1].copy()

subset_iteracao

subset_iteracao = iteracao_prompt(subset_iteracao, 4)

subset_iteracao = iteracao_prompt(subset_iteracao, 5)

subset_iteracao

def definir_area_moda(questao):
    quantidade = Counter([questao['area_1'], questao['area_2'], questao['area_3']]) #, questao['area_4'], questao['area_5']])
    moda, _ = quantidade.most_common(1)[0]

    return moda

subset_iteracao['area_final'] = subset_iteracao.apply(definir_area_moda, axis = 1)

subset_iteracao

poscomp_ds.update(subset_iteracao)

"""## Finalização: mapeamento para áreas"""

mapeamento_matematica = ['']
mapeamento_matematica.extend(list(areas_matematica.keys()))

mapeamento_fundamentos = ['']
mapeamento_fundamentos.extend(list(areas_fundamentos.keys()))

mapeamento_tecnologia = ['']
mapeamento_tecnologia.extend(list(areas_tecnologia.keys()))

mapeamento_nomes = {
  'Matemática': mapeamento_matematica,
  'Fundamentos da Computação': mapeamento_fundamentos,
  'Tecnologia de Computação': mapeamento_tecnologia
}

def mapear_nome(questao):
  return mapeamento_nomes[questao['area_conhecimento']][int(questao['area_final'])]

poscomp_ds['area_final_texto'] = poscomp_ds.apply(mapear_nome, axis = 1)

"""# Validação das áreas (POSCOMP 2019 e 2022)"""

poscomp_ds = pd.read_csv('poscomp_ds_areas_final.csv')
colunas_interesse = [
  'id',
  'enunciado',
  'area_conhecimento',
  'tokens_prompt',
  'texto_completo',
  'area_final_texto',
]
poscomp_ds = poscomp_ds[colunas_interesse]

poscomp_ds.head(5)

areas_verdadeiras = pd.read_csv('areas_verdadeiras.csv')

areas_verdadeiras.head()

poscomp_ds_areas = poscomp_ds.merge(areas_verdadeiras, on = 'id')

poscomp_ds_areas.head(5)

"""### Observar confusões"""

def get_contagem(ds):
  return pd.crosstab(ds['area_final_texto'], ds['area_verdadeira'])

ds_matematica = poscomp_ds_areas[poscomp_ds_areas['area_conhecimento'] == 'Matemática']
ds_fundamentos = poscomp_ds_areas[poscomp_ds_areas['area_conhecimento'] == 'Fundamentos da Computação']
ds_tecnologia = poscomp_ds_areas[poscomp_ds_areas['area_conhecimento'] == 'Tecnologia de Computação']

import seaborn as sns
import matplotlib.pyplot as plt

def plotar_contagem(ds):
  contagem = get_contagem(ds)
  highlight = contagem.copy()
  for i in highlight.index:
      for j in highlight.columns:
          if i.lower() == j.lower():
              highlight.loc[i, j] = 0  # zero para matches
          else:
              highlight.loc[i, j] = contagem.loc[i, j]  # mantém valores diferentes

  # Plot
  plt.figure(figsize=(6, 5))
  sns.heatmap(contagem, annot=True, fmt='d', cmap='Grays', cbar=False)

  # Sobreposição para destacar os não-matches
  sns.heatmap(highlight, mask=highlight==0, annot=False, cmap='Reds', alpha=.5, cbar=False)

  plt.title('Matriz de associações entre categorias')
  plt.xlabel('Área verdadeira')
  plt.ylabel('Área do Llama')
  plt.show()

plotar_contagem(ds_matematica)

plotar_contagem(ds_fundamentos)

poscomp_ds_areas

poscomp_ds_areas[poscomp_ds_areas['match'] == False].to_csv('oi.csv')

plotar_contagem(ds_tecnologia)

poscomp_ds_areas['match'] = poscomp_ds_areas['area_verdadeira'].str.lower() == poscomp_ds_areas['area_final_texto'].str.lower()

poscomp_ds_areas['match'].value_counts()

"""# Self-Refine (ajustes de áreas comumente confundidas)

## Matemática
"""

qtd_matematica = len(poscomp_ds[poscomp_ds['area_conhecimento'] == 'Matemática'])
categorias_matematica = len(areas_matematica.keys())
print(f"Média de questões por categoria: {qtd_matematica / categorias_matematica:.0f}")

# 3 * qtd_matematica / (6 * 3 + 2)

poscomp_ds[poscomp_ds['area_conhecimento'] == 'Matemática']['area_final_texto'].value_counts()

"""## Tecnologia de Computação"""

qtd_tecnologia = len(poscomp_ds[poscomp_ds['area_conhecimento'] == 'Tecnologia de Computação'])
categorias_tecnologia = len(areas_tecnologia.keys())
print(f"Média de questões por categoria: {qtd_tecnologia / categorias_tecnologia:.0f}")

(qtd_tecnologia / 20) * 3

poscomp_ds[poscomp_ds['area_conhecimento'] == 'Tecnologia de Computação']['area_final_texto'].value_counts()

"""## Fundamentos da Computação"""

qtd_fundamentos = len(poscomp_ds[poscomp_ds['area_conhecimento'] == 'Fundamentos da Computação'])
categorias_fundamentos = len(areas_fundamentos.keys())
print(f"Média de questões por categoria: {qtd_fundamentos / categorias_fundamentos:.0f}")

poscomp_ds[poscomp_ds['area_conhecimento'] == 'Fundamentos da Computação']['area_final_texto'].value_counts()

"""## Considerar áreas mais desbalanceadas para refinar"""

SYSTEM_PROMPT_REFINE = """Você é um revisor automático de classificações. Você receberá uma questão, a área originalmente atribuída e uma ou duas áreas alternativas.
Seu papel é refletir e decidir qual das áreas representa melhor o conteúdo da questão.
Ao final, responda apenas com o número correspondente à área escolhida. Nenhum outro texto deve ser incluído."""

n_tokens_prompt = len(tokenizer(SYSTEM_PROMPT_REFINE)['input_ids'])
print(n_tokens_prompt)

def representar_area(area_conhecimento, area):
  areas = conteudo_poscomp[area_conhecimento]
  n_area = list(areas.keys()).index(area) + 1
  return f"{n_area}. {area} (subáreas: {'; '.join(areas[area])})"

mapeamento_refinamento = {
  'Álgebra Linear': ['Geometria Analítica'],
  'Lógica Matemática': ['Matemática Discreta'],

  'Inteligência Artificial': ['Banco de Dados', 'Processamento de Imagens'],
  'Banco de Dados': ['Sistemas Distribuídos'],

  'Linguagens de Programação': ['Algoritmos e Estrutura de Dados', 'Técnicas de Programação'],
  'Arquitetura e Organização de Computadores': ['Circuitos Digitais'],
  'Sistemas Operacionais': ['Organização de Arquivos e Dados'],
  'Algoritmos e Estrutura de Dados': ['Análise de Algoritmos', 'Organização de Arquivos e Dados', 'Teoria dos Grafos']
}

filtro_mapeamento = poscomp_ds[poscomp_ds['area_final_texto'].isin(mapeamento_refinamento.keys())]

len(filtro_mapeamento)

def gerar_prompt_refinamento(questao):
  area = questao['area_final_texto']
  area_conhecimento = questao['area_conhecimento']
  areas_alternativas = mapeamento_refinamento[area]
  plural = 's' if len(areas_alternativas) > 1 else ''
  areas_string = '\n'.join(representar_area(area_conhecimento, area_alternativa) for area_alternativa in areas_alternativas)

  prompt = f"""Questão:
{questao['texto_substituido_parcial']}

Área original:
{representar_area(area_conhecimento, area)}

Área{plural} alternativa{plural}:
{areas_string}

Responda apenas com o número da área correspondente:
"""
  return prompt

original = pd.read_json('dataset.json')
original.drop_duplicates(subset = ['id'], inplace = True)
original = original.sort_values(by=['id'])
original.reset_index(drop = True, inplace = True)

poscomp_ds = pd.read_csv('poscomp_ds_areas_final_completo.csv')

import ast
poscomp_ds['alternativas'] = poscomp_ds['alternativas'].apply(ast.literal_eval)

poscomp_ds.dtypes

print(gerar_prompt_refinamento(poscomp_ds[poscomp_ds['area_final_texto'] == 'Algoritmos e Estrutura de Dados'].iloc[-1]))

filtro_refinamento = poscomp_ds[poscomp_ds['area_final_texto'].isin(mapeamento_refinamento.keys())]

len(filtro_refinamento)

filtro_refinamento['iteracao_1'] = filtro_refinamento.progress_apply(lambda x: get_completion(gerar_prompt_refinamento(x), "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT_REFINE), axis = 1)

filtro_refinamento['iteracao_2'] = filtro_refinamento.progress_apply(lambda x: get_completion(gerar_prompt_refinamento(x), "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT_REFINE), axis = 1)

filtro_refinamento['iteracao_3'] = filtro_refinamento.progress_apply(lambda x: get_completion(gerar_prompt_refinamento(x), "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT_REFINE), axis = 1)

filtro_refinamento

filtro_refinamento['area_1'] = filtro_refinamento['iteracao_1'].apply(lambda x: int(x.choices[0].message.content))
filtro_refinamento['custo_1'] = filtro_refinamento['iteracao_1'].apply(lambda x: x.usage.estimated_cost)
filtro_refinamento['area_2'] = filtro_refinamento['iteracao_2'].apply(lambda x: int(x.choices[0].message.content))
filtro_refinamento['custo_2'] = filtro_refinamento['iteracao_2'].apply(lambda x: x.usage.estimated_cost)
filtro_refinamento['area_3'] = filtro_refinamento['iteracao_3'].apply(lambda x: int(x.choices[0].message.content))
filtro_refinamento['custo_3'] = filtro_refinamento['iteracao_3'].apply(lambda x: x.usage.estimated_cost)

filtro_refinamento['custo_3'].sum()

filtro_refinamento.to_csv('v4.csv')

filtro_refinamento['area_final'] = filtro_refinamento.apply(definir_area, axis = 1)

filtro_refinamento_sc = filtro_refinamento[filtro_refinamento['area_final'] == -1]

filtro_refinamento_sc['iteracao_4'] = filtro_refinamento_sc.progress_apply(lambda x: get_completion(gerar_prompt_refinamento(x), "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT_REFINE), axis = 1)

filtro_refinamento_sc['iteracao_5'] = filtro_refinamento_sc.progress_apply(lambda x: get_completion(gerar_prompt_refinamento(x), "meta-llama/Llama-3.3-70B-Instruct", SYSTEM_PROMPT_REFINE), axis = 1)

filtro_refinamento_sc['area_4'] = filtro_refinamento_sc['iteracao_4'].apply(lambda x: int(x.choices[0].message.content))
filtro_refinamento_sc['area_5'] = filtro_refinamento_sc['iteracao_5'].apply(lambda x: int(x.choices[0].message.content))

filtro_refinamento_sc['area_final'] = filtro_refinamento_sc.apply(definir_area_moda, axis = 1)

refinados[refinados['id'] == '2019-30']['area_final']

filtro_refinamento_sc

filtro_refinamento.update(filtro_refinamento_sc)

filtro_refinamento.to_csv('final.csv')

custo = filtro_mapeamento['custo_n'].sum() / len(filtro_mapeamento)
print(f'Custo por prompt por iteração do refinamento:     ${custo:.6f}')
print(f'Estimativa total por iteração (todos os prompts): ${custo * n_total_refinamento:.6f}')

# Depois da validação, 12 novos acertos e 1 erro novo. [117/132] + 8% acurácia

import pandas as pd
from collections import Counter

refinados = pd.read_csv('v4.csv')

refinados = refinados[['id', 'enunciado', 'area_conhecimento', 'tokens_prompt',
       'texto_completo', 'area_final_texto', 'comandos_latex',
       'texto_substituido', 'edicao', 'numero', 'alternativas', 'area',
       'subarea', 'dificuldade', 'gabarito', 'solucao',
       'dificuldade_experimental', 'alternativas_str_completo',
       'alternativas_str_parcial', 'texto_parcial',
       'texto_substituido_parcial', 'iteracao_1', 'area_1', 'custo_1',
       'iteracao_2', 'area_2', 'custo_2', 'iteracao_3', 'area_3', 'custo_3']]

refinados['area_final'] = refinados.apply(definir_area_moda, axis = 1)

refinados['area_final_texto'] = refinados.apply(mapear_nome, axis = 1)

refinados.to_csv('refinados.csv', index = False)