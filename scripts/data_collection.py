# -*- coding: utf-8 -*-
"""Extração de Questões.ipynb

Automatically generated by Colab.

# Extração de questões do POSCOMP

## Instalação de Dependências
"""

!pip install pdfplumber pdf2image pytesseract

!apt-get install poppler-utils
!sudo apt-get install tesseract-ocr-por

"""## Funções para extração de texto dos PDFs

Como o formato das provas varia bastante, faz-se necessário utilizar diferentes abordagens para extração dos textos dos PDFs.

### Extração de texto completo de cada página

Abordagem de extração de todo o texto de cada página. Funciona para edições melhor estruturadas, com indicação de início de cada questão: 2015 a 2024.
"""

import re, pdfplumber

def extract_text_from_pdf(pdf_path, margins, start_page, regex_substitutions = []):
  questions_text = []

  margin_top, margin_bottom, margin_left, margin_right = margins

  with pdfplumber.open(pdf_path) as pdf:
    for page in pdf.pages[start_page:]:
      width = page.width
      height = page.height

      cropped_page = page.within_bbox((
        margin_left,
        margin_top,
        width - margin_right,
        height - margin_bottom
      ))

      page_text = cropped_page.extract_text(x_tolerance = 0.5)

      print(page_text)

      for (original, substitution) in regex_substitutions:
        page_text = re.sub(original, substitution, page_text)

      questions_text.extend([string for string in page_text.split('QUESTÃO ') if re.match(r"^(\d+) –", string)])

  return questions_text

"""### Extração de texto de cada linha da página

Abordagem de extração de texto por linha em cada página. Funciona para edições menos bem estruturadas, que utilizam identações para indicar o início da questão: 2004 a 2007, 2010 a 2014.
"""

def extract_lines_from_pdf(pdf_path, margins, start_page, problem_regex, x0_threshold = 75, end_page = 0):
  questions_text = []

  margin_top, margin_bottom, margin_left, margin_right = margins

  with pdfplumber.open(pdf_path) as pdf:
    if end_page == 0:
      end_page = len(pdf.pages)

    for page in pdf.pages[start_page:end_page]:
      width = page.width
      height = page.height

      cropped_page = page.within_bbox((
          margin_left,
          margin_top,
          width - margin_right,
          height - margin_bottom
      ))

      lines = cropped_page.extract_text_lines(x_tolerance = 0.5, y_tolerance = 4)

      curr_question = []

      # Workaround para questões que não são finalizadas numa mesma página.
      if lines[0]['x0'] >= x0_threshold and len(questions_text) > 0:
       curr_question = [questions_text.pop()]

      for line in lines:
        if line['x0'] < x0_threshold:
          match = re.match(problem_regex, line['text'])

          if match:
            problem_number = match.group(1)
            problem_text = match.group(2)
            if curr_question:
              questions_text.append('\n'.join(curr_question))
            curr_question = [f'{problem_number} – {problem_text}']
          else:
            curr_question.append(line['text']) # prova de 2002
        else:
          if curr_question:
            curr_question.append(line['text'])
      if curr_question:
          questions_text.append('\n'.join(curr_question))

  return questions_text

"""### Extração de texto a partir de PDF transformado em imagem

Algumas provas não podem ser lidas de maneira tradicional devido à codificação dos PDFs. Dessa forma, transforma-se cada página em uma imagem e utiliza-se OCR (Reconhecimento Ótico de Caracteres) para fazer a leitura.
"""

from pdf2image import convert_from_path
import pytesseract

def convert_points_to_pixels(bbox_points, dpi = 300):
    scale = dpi / 72
    return tuple(int(coord * scale) for coord in bbox_points)

def extract_text_from_pdf_as_image(pdf_path, margins, start_page, end_page = 0):
    bbox = convert_points_to_pixels(margins)

    pages = convert_from_path(pdf_path, dpi = 300)

    if end_page == 0:
      end_page = len(pages)

    pages = pages[start_page:end_page]
    questions_text = []

    for page in pages:
        cropped_page = page.crop(bbox)
        page_text = pytesseract.image_to_string(cropped_page, lang = 'por')

        questions_text.extend([string for string in page_text.split('Questão ') if re.match(r"^(\d+)\.\s*\[.+\]", string)])

    formatted_questions = []

    for question in questions_text:
      match = re.match(r"^(\d+)\.\s*\[.+\](.+)", question, flags = re.DOTALL)
      problem_id = match.group(1)
      problem_text = match.group(2).strip()

      formatted_questions.append(f'{problem_id} – {problem_text}')

    return formatted_questions

"""## Transformação de questões para o formato desejado

Nas etapas anteriores, as questões já foram transformadas para uma extração praticamente unificada.
"""

def map_problem_area(problem_number):
  if problem_number <= 20:
    return 'Matemática'
  if problem_number <= 50:
    return 'Fundamentos da Computação'
  return 'Tecnologia de Computação'

def extract_problem_from_text(problem_text, year, alternatives):
  splitted = problem_text.split('\n')

  line_index = 0

  print(splitted[line_index])
  match = re.match(r'^(\d+) – *(.+)', splitted[line_index])
  problem_number = int(match.group(1))
  problem_text = match.group(2)

  line_index += 1

  while line_index < len(splitted) and not re.match(fr"{alternatives[0]}", splitted[line_index]):
    problem_text += '\n'
    problem_text += splitted[line_index]
    line_index += 1

  curr_alternative = 0
  alternative_texts = []
  curr_text = ''

  for curr_alternative in range(len(alternatives)):
    while line_index < len(splitted) and (curr_alternative == len(alternatives) - 1 or not re.match(fr"{alternatives[curr_alternative + 1]}", splitted[line_index])):
      curr_text += splitted[line_index]
      curr_text += '\n'
      line_index += 1

    alternative_texts.append(curr_text.strip())
    curr_alternative += 1
    curr_text = ''

  json = {
    'edicao': year,
    'id': f'{year}-{str(problem_number).zfill(2)}',
    'numero': problem_number,
    'enunciado': problem_text,
    'alternativas': alternative_texts,
    'area_conhecimento': map_problem_area(problem_number),
    'area': '',
    'subarea': '',
    'dificuldade': '',
    'gabarito': '',
    'solucao': '',
  }

  return json

"""## Configurações para extração de cada edição

Cada edição tem suas especificidades quanto à estrutura e formatação da prova. Nas edições mais recentes (2016 em diante), tem se mantido um mesmo padrão.
"""

LINES = 'LINES'

configs = [
  {
    'edicao': 2024,
    'margins': [45, 25, 25, 25],
    'start_page': 1,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2023,
    'margins': [45, 25, 25, 25],
    'start_page': 1,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2022,
    'margins': [45, 25, 25, 25],
    'start_page': 2,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2019,
    'margins': [45, 30, 25, 25],
    'start_page': 2,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2018,
    'margins': [45, 45, 25, 25],
    'start_page': 2,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2017,
    'margins': [45, 45, 25, 25],
    'start_page': 2,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2016,
    'margins': [45, 45, 25, 25],
    'start_page': 2,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2015,
    'margins': [45, 45, 25, 25],
    'start_page': 1,
    'regex_substitutions': [
      ('▬\s*RASCUNHO\s*▬+', ''),
      (r'▬\s*QUESTÃO\s*(\d+)\s*▬+\n', r'QUESTÃO \1 – ')
    ],
    'alternatives_format': ['\(A\)', '\(B\)', '\(C\)', '\(D\)', '\(E\)']
  },
  {
    'edicao': 2014,
    'margins': [80, 100, 25, 25],
    'start_page': 2,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+) (.+)',
  },
  {
    'edicao': 2013,
    'margins': [80, 100, 25, 25],
    'start_page': 2,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+) (.+)',
  },
  {
    'edicao': 2012,
    'margins': [80, 100, 25, 25],
    'start_page': 2,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+) (.+)',
  },
  {
    'edicao': 2011,
    'margins': [80, 100, 25, 25],
    'start_page': 2,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+) (.+)',
  },
  {
    'edicao': 2010,
    'margins': [80, 100, 25, 25],
    'start_page': 2,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+)\) (.+)',
  },
  {
    'edicao': 2009,
    'margins': [85, 70, 550, 780],
    'start_page': 1,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
  },
  {
    'edicao': 2008,
    'margins': [55, 55, 25, 25],
    'start_page': 1,
    'alternatives_format': ['A\)', 'B\)', 'C\)', 'D\)', 'E\)'],
    'regex_substitutions': [
      (r'Questão (\d+)\n', r'QUESTÃO \1 – ')
    ],
  },
  {
    'edicao': 2007,
    'margins': [80, 80, 25, 25],
    'start_page': 2,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+\[.+\](.*)',
  },
  {
    'edicao': 2006,
    'margins': [80, 80, 25, 25],
    'start_page': 2,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+\[.+\](.*)',
  },
  {
    'edicao': 2005,
    'margins': [80, 80, 25, 25],
    'start_page': 2,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
  },
  {
    'edicao': 2004,
    'margins': [80, 80, 25, 25],
    'start_page': 2,
    'last_page': 18,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
  },
  {
    'edicao': 2004,
    'margins': [80, 80, 15, 15],
    'start_page': 18,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+)\)\s+(.*)',
  },
  {
    'edicao': 2002,
    'margins': [80, 80, 25, 25],
    'start_page': 14,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
    'x0_threshold': 90,
  },
  {
    'edicao': 2003,
    'margins': [0, 80, 25, 25],
    'start_page': 0,
    'last_page': 7,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
    'x0_threshold': 105
  },
  {
    'edicao': 2003,
    'margins': [0, 80, 25, 25],
    'start_page': 16,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
    'x0_threshold': 65,
    'strategy': LINES
  },
  {
    'edicao': 2002,
    'margins': [40, 80, 25, 25],
    'start_page': 0,
    'alternatives_format': ['\(a\)', '\(b\)', '\(c\)', '\(d\)', '\(e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
    'x0_threshold': 90,
    'last_page': 6,
  },
  {
    'edicao': 2002,
    'margins': [80, 80, 25, 25],
    'start_page': 14,
    'alternatives_format': ['a\)', 'b\)', 'c\)', 'd\)', 'e\)'],
    'problem_regex': r'^(\d+)\.\s+(.*)',
    'x0_threshold': 90,
  },
]

from pdf2image import convert_from_path
import pytesseract

def convert_points_to_pixels(bbox_points, dpi = 300):
    scale = dpi / 72
    return tuple(int(coord * scale) for coord in bbox_points)

def extract_text_from_pdf_as_image(pdf_path, margins, start_page, end_page = 0):
    bbox = convert_points_to_pixels(margins)

    pages = convert_from_path(pdf_path, dpi = 300)

    if end_page == 0:
      end_page = len(pages)

    pages = pages[start_page:end_page]
    questions_text = []

    for page in pages:
        cropped_page = page.crop(bbox)
        page_text = pytesseract.image_to_string(cropped_page, lang = 'por')
        print(page_text)

        questions_text.extend([string for string in page_text.split('Questão ') if re.match(r"^(\d+)\.\s*\[.+\]", string)])

    formatted_questions = []

    for question in questions_text:
      match = re.match(r"^(\d+)\.\s*\[.+\](.+)", question, flags = re.DOTALL)
      problem_id = match.group(1)
      problem_text = match.group(2).strip()

      formatted_questions.append(f'{problem_id} – {problem_text}')

    return formatted_questions

"""## Execução da extração de questões

Com as funções devidamente definidas, executa-se a extração das questões, especificando qual método utilizar para cada edição.
"""

jsons = []

for config in configs:
  pdf_text = []

  edicao, margins, start_page, alternatives_format = config['edicao'], config['margins'], config['start_page'], config['alternatives_format']
  regex_substitutions = config.get('regex_substitutions', [])
  problem_regex = config.get('problem_regex', '')
  x0_threshold = config.get('x0_threshold', 200)
  last_page = config.get('last_page', 0)

  print(f'Processando POSCOMP {edicao}...')

  if edicao <= 2003:
    pdf_text = extract_lines_from_pdf(f"{edicao}.pdf", margins, start_page, problem_regex, x0_threshold, last_page)
  elif edicao == 2009:
    pdf_text = extract_text_from_pdf_as_image(f"{edicao}.pdf", tuple(margins), start_page)
  elif edicao <= 2007:
    pdf_text = extract_lines_from_pdf(f"{edicao}.pdf", margins, start_page, problem_regex, 85, config.get('last_page', 0))
  elif edicao == 2008 or edicao > 2014:
    pdf_text = extract_text_from_pdf(f"{edicao}.pdf", margins, start_page, regex_substitutions)
  else:
    pdf_text = extract_lines_from_pdf(f"{edicao}.pdf", margins, start_page, problem_regex)

  for index in range(1, len(pdf_text)):
    if index == 4 or index == 12 or index == 16 or index == 22: continue
    jsons.append(extract_problem_from_text(pdf_text[index], edicao, alternatives_format))

"""### Exportação de JSONs"""

import json

with open("questoes.json", "w") as outfile:
    json.dump(jsons, outfile)

"""# Extração de gabaritos"""

todos_gabaritos = []

for ano in range(2002, 2025):
  if ano == 2020 or ano == 2021:
    continue

  gabaritos = []
  if ano == 2002:
    gabaritos = extract_text_from_pdf(2002, 0, '^([0-9]+)-(\S+)')
  elif ano == 2005:
    gabaritos = extract_text_from_pdf(2005, 0, '^([0-9]+). \((\S+)\)')
  elif ano == 2006:
    gabaritos = extract_text_from_pdf(2006, 0, '^([0-9]+)- (\S+)')
  elif ano == 2007:
    gabaritos = extract_text_from_pdf(2007, 0, '^([0-9]+). (\S+)')
  elif ano == 2018:
    gabaritos = [(index + 1, gabarito) for index, gabarito in enumerate('D A B E E B C A B B B C D C C D D E C A C A A B E D B D E C E E E E E B C D C D D D E D B B C B C E D C A A A D A C B B A D * A B E C D C A'.split())]
  elif ano == 2024:
    gabaritos = extract_text_from_pdf_2024()
  else:
    gabaritos = extract_text_from_pdf(ano)

  for index in range(len(gabaritos)):
    gabarito = gabaritos[index][1].upper()
    if gabarito[0] == '(':
      gabarito = gabarito[1]
    if gabarito not in set(['A', 'B', 'C', 'D', 'E']):
      gabarito = 'ANULADA'

    todos_gabaritos.append({ 'id': f'{ano}-{index + 1:02}', 'gabarito': gabarito })

import json

with open("gabaritos.json", "w") as outfile:
    json.dump(todos_gabaritos, outfile)